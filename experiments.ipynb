{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0532bb85",
   "metadata": {},
   "source": [
    "# ESBMC-AI AICodeRepair Experiments\n",
    "\n",
    "Using the knowledge from the [previous single iteration experiments](https://github.com/Yiannis128/aicoderepair_llmtests), implement findings into ESBMC-AI and re-run tests to measure performance.\n",
    "\n",
    "## Methodology\n",
    "\n",
    "Use the same samples as the previous experiments to directly compare performance.\n",
    "\n",
    "For each sample run:\n",
    "\n",
    "1. Show only the latest code state (last code generation) in the iterative APR loop, and original iteration:\n",
    "    * Single line\n",
    "    * Contextual\n",
    "2. Show all the previous code states:\n",
    "    * Single line\n",
    "    * Contextual\n",
    "3. Data Analysis:\n",
    "    1. Determine the optimal way to show the history of code\n",
    "    2. Which number of iterations is the best one?\n",
    "    3. What is the number of lines of code that change during repair?\n",
    "\n",
    "Total Experiments:\n",
    "* We will use the best prompt template + role + ESBMC output type from the previous experiments: 2\n",
    "* We have 100 experiments.\n",
    "\n",
    "## Files Needed\n",
    "\n",
    "This notebook will use:\n",
    "\n",
    "* `samples`\n",
    "* `esbmc_output`\n",
    "* `includes`\n",
    "\n",
    "All other files are generated as part of the pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28acf71",
   "metadata": {},
   "source": [
    "# Running Experiments with GPT 3.5 Turbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e380fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from io import TextIOWrapper\n",
    "from time import time\n",
    "from math import floor\n",
    "from subprocess import run, PIPE, STDOUT\n",
    "\n",
    "import tiktoken\n",
    "from time import sleep\n",
    "from typing import Optional\n",
    "from dotenv import get_key as load_dotenv, get_key\n",
    "from openai import OpenAI, Completion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e26098",
   "metadata": {},
   "source": [
    "### AI Params + Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f94c5c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_TOKENS: int = 16385\n",
    "os.environ[\"ESBMC_AI_CFG_PATH\"] = \"./config.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab012c10",
   "metadata": {},
   "source": [
    "### Initializing Logger\n",
    "Log everything using these easy custom print and write functions. Need to beware that opening log.txt may display outdated state until buffer is properly flushed. Editing the log file will result in corruption until `log_file.close()` is called."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0517fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def close_logger():\n",
    "    # Close logger\n",
    "    try:\n",
    "        if not log_file.closed:\n",
    "            log_file.close()\n",
    "    except NameError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbde1fa4-83d7-4279-b0e4-861c21b798a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "close_logger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36458e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize logger.\n",
    "def init_logger(file_path: str = \"log.txt\"):\n",
    "    log_file: TextIOWrapper\n",
    "    try:\n",
    "        log_file = open(file_path, \"a\")\n",
    "    except (NameError, ValueError) as e:\n",
    "        log_file = open(\"log.txt\", \"w\")\n",
    "    return log_file\n",
    "\n",
    "def log_str(text: str = \"\") -> None:\n",
    "    assert not log_file.closed, \"The log file is closed.\"\n",
    "    if len(text) == 0:\n",
    "        log_file.write(\"\\n\")\n",
    "    else:\n",
    "        log_file.write(f\"Log: {time()}: {text}\\n\")\n",
    "    \n",
    "def print_and_log(text: str = \"\") -> None:\n",
    "    assert not log_file.closed, \"The log file is closed.\"\n",
    "    if len(text) == 0:\n",
    "        log_file.write(\"\\n\")\n",
    "        print()\n",
    "    else:\n",
    "        text = str(time()) + \": \" + text\n",
    "        log_file.write(\"Log: \" + text + \"\\n\")\n",
    "        print(text)\n",
    "\n",
    "def print_logging_session_message():\n",
    "    print_and_log(\"Notice: Starting new logging session.\")\n",
    "    log_file.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b871538f",
   "metadata": {},
   "source": [
    "### Load and Parse Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c54fa6",
   "metadata": {},
   "source": [
    "##### ESBMC Extract Parts of Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "884403fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all the sample names to process as part of the experiments. They NEED to be sorted.\n",
    "sample_names: list[str] = sorted(os.listdir(f\"samples\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b3a992",
   "metadata": {},
   "source": [
    "### Define Prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035d9fa7",
   "metadata": {},
   "source": [
    "The following prompts are going to be iterated through. The prompts `simple_prompts_no_esbmc` and `simple_prompts` are the baseline prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "afd2327c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------\n",
      "From now on, act as an Automated code repair tool that repairs AI C code. You will be shown AI C code, along with ESBMC output. Pay close attention to the ESBMC output, which contains a stack trace along with what type of error has occurred and its location. Provide the repaired C code as output, as would an Automated code repair tool. Aside from the corrected source code, do not output any other text. The code is\n",
      "\n",
      "```c\n",
      "{source_code}\n",
      "```\n",
      "\n",
      "The ESBMC output is\n",
      "\n",
      "```\n",
      "{esbmc_output}\n",
      "```\n",
      "\n",
      "--------------------------\n",
      "From now on, act as an Automated code repair tool that repairs AI C code. You will be shown a line of AI C code, along with ESBMC output. Pay close attention to the ESBMC output, which contains what type of error has occurred and its location. Provide the repaired C code as output, as would an Automated code repair tool. Aside from the corrected line of source code, do not output any other text. The code is\n",
      "\n",
      "```c\n",
      "{source_code}\n",
      "```\n",
      "\n",
      "The ESBMC output is\n",
      "\n",
      "```\n",
      "{esbmc_output}\n",
      "```\n",
      "Guideline: Always prefer to repair using a single line of C code, unless neccessary.\n",
      "Guideline: Read the error in the ESBMC output and try to repair the fault.\n",
      "--------------------------\n",
      "From now on, act as an Automated code repair tool that repairs AI C code. You will be shown AI C code, along with ESBMC output. Pay close attention to the ESBMC output, which contains a stack trace along with what type of error has occurred and its location. Provide the repaired C code as output, as would an Automated code repair tool. Aside from the corrected source code, do not output any other text. The ESBMC output is\n",
      "\n",
      "```\n",
      "{esbmc_output}\n",
      "```\n",
      "\n",
      "The source code is\n",
      "\n",
      "```c\n",
      "{source_code}\n",
      "```\n",
      "--------------------------\n",
      "From now on, act as an Automated code repair tool that repairs AI C code. You will be shown a line of AI C code, along with ESBMC output. Pay close attention to the ESBMC output, which contains what type of error has occurred and its location. Provide the repaired C code as output, as would an Automated code repair tool. Aside from the corrected line of source code, do not output any other text. The ESBMC output is\n",
      "\n",
      "```\n",
      "{esbmc_output}\n",
      "```\n",
      "\n",
      "The source code is\n",
      "\n",
      "```c\n",
      "{source_code}\n",
      "```\n",
      "Guideline: Always prefer to repair using a single line of C code, unless neccessary.\n",
      "Guideline: Read the error in the ESBMC output and try to repair the fault.\n",
      "--------------------------\n",
      "{'system': [{'role': 'System', 'content': 'You are an secure code generator that parses vulnerable source code, and output from a program called ESBMC, which contains vulnerability information about the source code. You should use the output from ESBMC to find the problem, and correct the source code. ESBMC is always correct. You shall add a NULL check for every heap allocation you make. From this point on, you can only reply in source code. You shall only output source code as whole. Reply OK if you understand.'}, {'role': 'AI', 'content': 'OK'}, {'role': 'Human', 'content': 'The following text is the source code of the program, reply OK if you understand:\\n\\n```c\\n{source_code}\\n```'}, {'role': 'AI', 'content': 'OK'}, {'role': 'Human', 'content': 'The following text is the output of ESBMC, reply OK if you understand:\\n\\n```\\n{esbmc_output}```'}, {'role': 'AI', 'content': 'OK'}], 'initial': 'Generate a correction for the source code provided. Show the code only. Do not reply with acknowledgements.'}\n"
     ]
    }
   ],
   "source": [
    "# Best prompts from LLM aicoderepair tests\n",
    "\n",
    "persona_prompt: list[str] = [\n",
    "    \"From now on, act as an {role} that repairs AI C code. You will be shown AI C code, along with ESBMC output. Pay close attention to the ESBMC output, which contains a stack trace along with what type of error has occurred and its location. Provide the repaired C code as output, as would an {role}. Aside from the corrected source code, do not output any other text. The code is\\n\\n```c\\n{source_code}\\n```\\n\\nThe ESBMC output is\\n\\n```\\n{esbmc_output}\\n```\\n\",\n",
    "    \"From now on, act as an {role} that repairs AI C code. You will be shown a line of AI C code, along with ESBMC output. Pay close attention to the ESBMC output, which contains what type of error has occurred and its location. Provide the repaired C code as output, as would an {role}. Aside from the corrected line of source code, do not output any other text. The code is\\n\\n```c\\n{source_code}\\n```\\n\\nThe ESBMC output is\\n\\n```\\n{esbmc_output}\\n```\\nGuideline: Always prefer to repair using a single line of C code, unless neccessary.\\nGuideline: Read the error in the ESBMC output and try to repair the fault.\",\n",
    "]\n",
    "\n",
    "persona_prompt_flipped: list[str] = [\n",
    "    \"From now on, act as an {role} that repairs AI C code. You will be shown AI C code, along with ESBMC output. Pay close attention to the ESBMC output, which contains a stack trace along with what type of error has occurred and its location. Provide the repaired C code as output, as would an {role}. Aside from the corrected source code, do not output any other text. The ESBMC output is\\n\\n```\\n{esbmc_output}\\n```\\n\\nThe source code is\\n\\n```c\\n{source_code}\\n```\",\n",
    "    \"From now on, act as an {role} that repairs AI C code. You will be shown a line of AI C code, along with ESBMC output. Pay close attention to the ESBMC output, which contains what type of error has occurred and its location. Provide the repaired C code as output, as would an {role}. Aside from the corrected line of source code, do not output any other text. The ESBMC output is\\n\\n```\\n{esbmc_output}\\n```\\n\\nThe source code is\\n\\n```c\\n{source_code}\\n```\\nGuideline: Always prefer to repair using a single line of C code, unless neccessary.\\nGuideline: Read the error in the ESBMC output and try to repair the fault.\",\n",
    "]\n",
    "\n",
    "old_prompt = {\n",
    "    \"system\": [\n",
    "    {\n",
    "      \"role\": \"System\",\n",
    "      \"content\": \"You are an secure code generator that parses vulnerable source code, and output from a program called ESBMC, which contains vulnerability information about the source code. You should use the output from ESBMC to find the problem, and correct the source code. ESBMC is always correct. You shall add a NULL check for every heap allocation you make. From this point on, you can only reply in source code. You shall only output source code as whole. Reply OK if you understand.\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"AI\",\n",
    "      \"content\": \"OK\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"Human\",\n",
    "      \"content\": \"The following text is the source code of the program, reply OK if you understand:\\n\\n```c\\n{source_code}\\n```\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"AI\",\n",
    "      \"content\": \"OK\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"Human\",\n",
    "      \"content\": \"The following text is the output of ESBMC, reply OK if you understand:\\n\\n```\\n{esbmc_output}```\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"AI\",\n",
    "      \"content\": \"OK\"\n",
    "    }\n",
    "  ],\n",
    "  \"initial\": \"Generate a correction for the source code provided. Show the code only. Do not reply with acknowledgements.\"\n",
    "}\n",
    "\n",
    "all_prompts: list = persona_prompt + persona_prompt_flipped\n",
    "persona_roles: str = \"Automated code repair tool\"\n",
    "all_prompts = [prompt.replace(\"{role}\", persona_roles) for prompt in all_prompts]\n",
    "\n",
    "# No role applied to original prompt\n",
    "all_prompts.append(old_prompt)\n",
    "    \n",
    "for prompt in all_prompts:\n",
    "    print(\"--------------------------\")\n",
    "    print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bfa4287",
   "metadata": {},
   "source": [
    "# Experiment Execution\n",
    "\n",
    "The source code and the ESBMC output is too large for the LLM's context length. 3 strategies are proposed to see if they can alleviate the problem:\n",
    "\n",
    "1. Constant: Split by line or by character no strucutre (Brutal split)\n",
    "2. ~~Structural: Split semantically (function by function)~~\n",
    "3. Contextual: Split from failure and show code before\n",
    "\n",
    "#### Notation\n",
    "\n",
    "Let `L={l1, l2, l3, ..., ln}` be the set of all line lengths and where `n` is the number of lines in `C` and where `lx` is the length of the `x`th line in `C`. So `C[l1]` is the length first line and so on... `E` represents the length of the line with the error and `e` is the index of that line in `L`, such that `E=L[e]=le`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1b467b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_esbmc_ai(file_name: str) -> str:\n",
    "    cmd = [\"pipenv\", \"run\", \"esbmc-ai\", \"-vvvrc\", \"fix-code\", file_name]\n",
    "    result = run(cmd, stdout=PIPE, stderr=STDOUT)\n",
    "    exit_code: int = result.returncode\n",
    "    output: str = result.stdout.decode(\"utf-8\")\n",
    "    return exit_code, output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d693c1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## ~~Contextual Strategy~~\n",
    "\n",
    "Involves getting the line at which the error has occured along with a ratio split of the lines before/after. In this case chose `85%` before and `10%` as we want to give as much information of how the code looked before the error, however, still include some lines after for context.\n",
    "\n",
    "The following variables are declared:\n",
    "* `LTOKENS=MAX_TOKENS*0.85` - The window of tokens to keep before the error line.\n",
    "* `UTOKENS=MAX_TOKENS*0.10` - The window of tokens to keep after the error line.\n",
    "\n",
    "The lower bound line index is calculated like so:\n",
    "1. We want the largest `il` such that `S = Σ{il=0}{e}(L[e-il]<=LTOKENS)`.\n",
    "2. The constraints of `S` are as follows: `0<=il<=e` and `0<=L[e-S:e]<=LTOKENS`.\n",
    "\n",
    "Similarly, the upper bound line index is calculated like so:\n",
    "1. We want the largest `iu` such that `S = Σ{iu=0}{e}(L[e+iu]<=UTOKENS)`.\n",
    "2. The constraints of `S` are as follows: `0<=iu<=n-e` and `0<=L[e:e+Su]<=UTOKENS`.\n",
    "\n",
    "The combined window will be: `L[e-lu:e+iu]` which will fill `95%` of `MAX_TOKENS`, the other `5%` will be allocated to the ESBMC output's counterexample stack-trace (and/)or violated property."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987a9125",
   "metadata": {},
   "source": [
    "#### Experimental Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05bb63d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_contextual_sample(\n",
    "        prompt_idx: int, \n",
    "        role_idx: int,\n",
    "        esbmc_output_type: str, \n",
    "        file_idx: int) -> None:\n",
    "    prompt: str = all_prompts[prompt_idx]\n",
    "    file_name_key: str = sorted(data_samples.keys())[file_idx]\n",
    "    role: str = persona_roles[role_idx]\n",
    "    \n",
    "    # Name will be sorted by experimental order. Not filename as common experiments can be\n",
    "    # found near eachother.\n",
    "    file_name: str = f\"{prompt_idx}.{role_idx}.{esbmc_output_type}.{file_idx}.{os.path.basename(file_name_key)}\"\n",
    "    \n",
    "    print_and_log()\n",
    "    print_and_log(f\"Notice: Checkpoint {file_name}\")\n",
    "    \n",
    "    # Get CE or VP output for ESBMC.\n",
    "    esbmc_output: str\n",
    "    if esbmc_output_type == \"ce\":\n",
    "        esbmc_output = data_esbmc_output[file_name_key]\n",
    "    else:\n",
    "        esbmc_output = data_vp_output[file_name_key]\n",
    "\n",
    "    esbmc_output = get_esbmc_output_sized(esbmc_output)\n",
    "\n",
    "    source_code: str = data_samples[file_name_key]\n",
    "    source_code_lines: list[str] = source_code.splitlines(True)\n",
    "    \n",
    "    # Get the used ESBMC output length in order to calculate how to add it to the prompt template.\n",
    "    esbmc_output_token_len: int = num_tokens_from_string(esbmc_output)\n",
    "\n",
    "    # TODO If we get errors here pass full esbmc output instead of trimmed.\n",
    "    err_line: int = get_source_code_err_line(esbmc_output)\n",
    "\n",
    "    # Trim the source code in order to give it to the LLM.\n",
    "    lower_bound: int = get_lower_bound(source_code_lines, err_line, esbmc_output_token_len * 0.9)\n",
    "    # The upper bound is inclusive.\n",
    "    upper_bound: int = get_upper_bound(source_code_lines, err_line, esbmc_output_token_len * 0.1)\n",
    "    trimmed_sc: str = \"\".join(source_code_lines[lower_bound:upper_bound+1])\n",
    "    \n",
    "    try:\n",
    "        log_str(f\"LLM Raw Input:\\n{get_llm_message(prompt, trimmed_sc, esbmc_output, role)}\")\n",
    "        \n",
    "        delta: float = time()\n",
    "        # Role will be passed, if the prompt does not contain {role} then it will be not used.\n",
    "        llm_output_raw = run_sample(prompt, trimmed_sc, esbmc_output, role)\n",
    "        delta = time() - delta\n",
    "\n",
    "        log_str(f\"Raw Response:\\n\\n{llm_output_raw}\")\n",
    "        print_and_log(f\"Notice: Duration: {delta}\")\n",
    "        \n",
    "        llm_output = get_code_from_solution(llm_output_raw)\n",
    "        log_str(f\"Extracted Code:\\n\\n{llm_output}\")\n",
    "        \n",
    "        # Save patch\n",
    "        with open(f\"results/{file_name}\", \"w\") as file:\n",
    "            file.write(llm_output)\n",
    "\n",
    "        # Stitch together patch\n",
    "        patched_source: str = apply_patch_brutal_replacement(source_code, llm_output, lower_bound, upper_bound)\n",
    "\n",
    "        # Save patched source\n",
    "        with open(f\"samples-patched/{file_name}\", \"w\") as file:\n",
    "            file.write(patched_source)\n",
    "    except Exception as e:\n",
    "        print_and_log(f\"Notice: error: {file_name_key}: {e}\")\n",
    "    \n",
    "    print_and_log()\n",
    "\n",
    "    log_file.flush()\n",
    "    \n",
    "    # Write progress\n",
    "    with open(\"progress.txt\", \"a\") as file:\n",
    "        # Write the file name and subdirectory in progress in order to know which file is being\n",
    "        # processed in what subdirectory.\n",
    "        file.write(f\"{file_name}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1989add9",
   "metadata": {},
   "source": [
    "#### Run Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1fc1f71",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print_and_log()\n",
    "print_and_log(\"Running Contextual Strategy\")\n",
    "\n",
    "# Loop through prompts\n",
    "for prompt_idx, prompt in enumerate(all_prompts):\n",
    "    print_and_log()\n",
    "    print_and_log(f\"Notice: Running new cycle with prompt ({prompt_idx})\")\n",
    "    # Try all the roles\n",
    "    # Check if a {role} tag is in the prompt string and use roles in that case.\n",
    "    role_count: int\n",
    "    if \"{role}\" in prompt:\n",
    "        print_and_log(\"Notice: Prompt has roles. Will cycle roles.\")\n",
    "        role_count = len(persona_roles)\n",
    "    else:\n",
    "        print_and_log(\"Notice: Prompt has no roles. Roles will not be cycled or used (0).\")\n",
    "        role_count = 1\n",
    "\n",
    "    # Loop through the different roles.\n",
    "    for role_idx in range(role_count):\n",
    "        # Loop through violated property ESBMC output and counterexample ESBMC output.\n",
    "        for esbmc_output_type in [\"ce\", \"vp\"]:\n",
    "            # Loop through files\n",
    "            for file_idx, file_name_key in enumerate(sorted(data_samples.keys())):\n",
    "                # Check if file has already been processed and skip.\n",
    "                if os.path.exists(\"progress.txt\"):\n",
    "                    with open(\"progress.txt\", \"r\") as file:\n",
    "                        progress_files: list[str] = file.read().splitlines()\n",
    "                        file_name: str = f\"{prompt_idx}.{role_idx}.{esbmc_output_type}.{file_idx}.{os.path.basename(file_name_key)}\"\n",
    "                        if file_name in progress_files:\n",
    "                            log_str(f\"Skipping already processed file: {file_name}\")\n",
    "                            continue\n",
    "\n",
    "                run_contextual_sample(\n",
    "                    prompt_idx=prompt_idx, \n",
    "                    role_idx=role_idx, \n",
    "                    file_idx=file_idx, \n",
    "                    esbmc_output_type=esbmc_output_type,\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb100a6",
   "metadata": {},
   "source": [
    "## Single Line Experiment\n",
    "\n",
    "Run ESBMC-AI with single line mode. ESBMC output type is vp."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db496ce1",
   "metadata": {},
   "source": [
    "### Config Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef7753ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def set_config_prompt(new_prompt: str | dict, temperature: float, save_dir: str = \".\") -> None:\n",
    "    \"\"\"Creates a new config with the provided prompt as the FCM initial prompt.\"\"\"\n",
    "    with open(\"config_template.json\", \"r\") as read_file:\n",
    "        file_content = json.load(read_file)\n",
    "    \n",
    "    file_content[\"chat_modes\"][\"generate_solution\"][\"temperature\"] = temperature\n",
    "    \n",
    "    if isinstance(new_prompt, str):\n",
    "        file_content[\"chat_modes\"][\"generate_solution\"][\"initial\"] = new_prompt\n",
    "    elif isinstance(new_prompt, dict):\n",
    "        file_content[\"chat_modes\"][\"generate_solution\"][\"system\"] = new_prompt[\"system\"]\n",
    "        file_content[\"chat_modes\"][\"generate_solution\"][\"initial\"] = new_prompt[\"initial\"]\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid type {type(new_prompt)}\")\n",
    "        \n",
    "    with open(f\"{save_dir}/config.json\", \"w\") as write_file:\n",
    "        json.dump(file_content, write_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf1462d3",
   "metadata": {},
   "source": [
    "### Run Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f2811a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_esbmc_ai_single_line(\n",
    "        prompt_idx: int,\n",
    "        file_idx: int,\n",
    "        save_dir: str,\n",
    "        exp_dir: str) -> None:\n",
    "    file_name: str = sample_names[file_idx]\n",
    "    \n",
    "    print_and_log()\n",
    "    print_and_log(f\"Notice: Checkpoint {file_idx}/{len(sample_names)} samples/{file_name}\")\n",
    "    \n",
    "    # Call ESBMC-AI\n",
    "    try:        \n",
    "        delta: float = time()\n",
    "        exit_code, esbmc_ai_output = run_esbmc_ai(f\"samples/{file_name}\")\n",
    "        delta = time() - delta\n",
    "\n",
    "        log_str(f\"Notice: ESBMC-AI Output:\\n{esbmc_ai_output}\")\n",
    "        print_and_log(f\"Notice: Duration: {delta}\")\n",
    "        \n",
    "        # Save output\n",
    "        with open(f\"{save_dir}/{file_name}\", \"w\") as file:\n",
    "            file.write(esbmc_ai_output)\n",
    "    except Exception as e:\n",
    "        print_and_log(f\"Notice: error: {file_name}: {e}\")\n",
    "    \n",
    "    print_and_log()\n",
    "\n",
    "    log_file.flush()\n",
    "    \n",
    "    # Write progress\n",
    "    with open(f\"{exp_dir}/progress-single-{prompt_idx}.txt\", \"a\") as file:\n",
    "        # Write the file name and subdirectory in progress in order to know which file is being\n",
    "        # processed in what subdirectory.\n",
    "        file.write(f\"{file_name}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c372262",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1713989262.7220867: Notice: Starting new logging session.\n",
      "\n",
      "1713989262.7324674: Running ESBMC-AI: Single Line\n",
      "\n",
      "1713989262.7325: Notice: Running new cycle with prompt (0): From now on, act as an Automated code repair tool that repairs AI C code. You will be shown AI C code, along with ESBMC output. Pay close attention to the ESBMC output, which contains a stack trace along with what type of error has occurred and its location. Provide the repaired C code as output, as would an Automated code repair tool. Aside from the corrected source code, do not output any other text. The code is\n",
      "\n",
      "```c\n",
      "{source_code}\n",
      "```\n",
      "\n",
      "The ESBMC output is\n",
      "\n",
      "```\n",
      "{esbmc_output}\n",
      "```\n",
      "\n",
      "1713989262.7380824: Creating new config.json from template with prompt: 0\n",
      "\n",
      "1713989262.7648926: Notice: Checkpoint 0/100 samples/cartpole_0_safe.c-amalgamation-74.c\n"
     ]
    }
   ],
   "source": [
    "for temperature in [\"0.0\", \"0.4\", \"0.7\", \"1.0\", \"1.3\"]:\n",
    "    temperature_path = f\"temperature_{temperature}_results\"\n",
    "    if not os.path.isdir(temperature_path):\n",
    "        os.mkdir(temperature_path)\n",
    "        \n",
    "    log_file = init_logger(file_path=f\"{temperature_path}/log.txt\")\n",
    "    print_logging_session_message()\n",
    "    \n",
    "    print_and_log()\n",
    "    print_and_log(\"Running ESBMC-AI: Single Line\")\n",
    "    \n",
    "    # Loop through prompts\n",
    "    for prompt_idx, prompt in enumerate(all_prompts):\n",
    "        print_and_log()\n",
    "        print_and_log(f\"Notice: Running new cycle with prompt ({prompt_idx}): {prompt}\")\n",
    "\n",
    "        results_dir: str = f\"{temperature_path}/results-{prompt_idx}\"\n",
    "        # Create directories if not made already\n",
    "        if not os.path.exists(results_dir):\n",
    "            os.mkdir(results_dir)\n",
    "\n",
    "        print_and_log(f\"Creating new config.json from template with prompt: {prompt_idx}\")\n",
    "        set_config_prompt(new_prompt=prompt, temperature=float(temperature))\n",
    "\n",
    "        # Loop through files\n",
    "        for file_idx, file_name in enumerate(sample_names):\n",
    "            # Check if file has already been processed and skip.\n",
    "            progress_file_path = f\"{temperature_path}/progress-single-{prompt_idx}.txt\"\n",
    "            if os.path.exists(progress_file_path):\n",
    "                with open(progress_file_path, \"r\") as file:\n",
    "                    progress_files: list[str] = file.read().splitlines()\n",
    "                    if file_name in progress_files:\n",
    "                        log_str(f\"Skipping already processed file: {file_name}\")\n",
    "                        continue\n",
    "\n",
    "            run_esbmc_ai_single_line(\n",
    "                prompt_idx=prompt_idx,\n",
    "                file_idx=file_idx, \n",
    "                save_dir=results_dir,\n",
    "                exp_dir=temperature_path,\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ab0e5c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## ~~3. Clang Feedback To LLM~~\n",
    "\n",
    "Perform a second iteration fix where the LLM is provided Clang feedback and asked to repair it. The results in `samples-patched` will be used along with `esbmc_output_1` (meaning 1st attempt). The results will be placed in `results-2` and `samples-patched-2`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a124d5f",
   "metadata": {},
   "source": [
    "### Load ESBMC Output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11d5bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "clang_file_keys: list[str] = sorted(os.listdir(f\"esbmc_output_1/\"))\n",
    "data_samples_1: dict[str, str] = {}\n",
    "data_esbmc_output_1: dict[str, str] = {}\n",
    "\n",
    "for file_name in clang_file_keys:\n",
    "    if not file_name.endswith(\".c\"):\n",
    "        continue\n",
    "    \n",
    "    # Read samples-patched (Generated previously)\n",
    "    with open(f\"samples-patched/{file_name}\", \"r\") as file:\n",
    "        data_samples_1[file_name] = file.read()\n",
    "\n",
    "    # Read esbmc_output_1 (Generated by running ./eval-esbmc.sh)\n",
    "    with open(f\"esbmc_output_1/{file_name}\", \"r\") as file:\n",
    "        data_esbmc_output_1[file_name] = file.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7ee1c3",
   "metadata": {},
   "source": [
    "### Create Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d097f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs: list[str] = [\"samples-patched-2\", \"results-2\"]\n",
    "\n",
    "for dir in dirs:\n",
    "    if not os.path.exists(dir):\n",
    "        os.mkdir(dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d1bdc00",
   "metadata": {},
   "source": [
    "### Get Error Line\n",
    "\n",
    "Clang reports errors differently, this method will be used to find the error line: `samples-patched/12.0.ce.36.cartpole_2_safe.c-amalgamation-43.c:177:1: error:`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347b8014",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_source_code_err_line_clang(esbmc_output: str, filepath: str) -> int:\n",
    "    \"\"\"Gets the error line reported in the clang output.\"\"\"\n",
    "    lines: list[str] = esbmc_output.splitlines()\n",
    "    for ix, line in enumerate(lines):\n",
    "        # Find the first line containing a filename along with error.\n",
    "        line_split: list[str] = line.split(\":\")\n",
    "        # Check for the filename\n",
    "        if line_split[0] == filepath and \" error\" in line_split[3]:\n",
    "            return int(line_split[1])\n",
    "            \n",
    "    raise Exception(f'Could not find error line in {file_name_key}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb5b900",
   "metadata": {},
   "source": [
    "### Run Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea7bc0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_contextual_sample_clang(\n",
    "        prompt_idx: int, \n",
    "        role_idx: int,\n",
    "        file_idx: int,\n",
    "        file_name_key: str) -> None:\n",
    "    prompt: str = all_prompts[prompt_idx]\n",
    "    role: str = persona_roles[role_idx]\n",
    "    \n",
    "    # Name will be sorted by experimental order. Not filename as common experiments can be\n",
    "    # found near eachother.\n",
    "    file_name: str = f\"{prompt_idx}.{role_idx}.{file_idx}.{os.path.basename(file_name_key)}\"\n",
    "    \n",
    "    print_and_log()\n",
    "    print_and_log(f\"Notice: Checkpoint {file_name}\")\n",
    "\n",
    "    esbmc_output: str = get_esbmc_output_sized(data_esbmc_output_1[file_name_key])\n",
    "\n",
    "    source_code: str = data_samples_1[file_name_key]\n",
    "    source_code_lines: list[str] = source_code.splitlines(True)\n",
    "    \n",
    "    # Get the used ESBMC output length in order to calculate how to add it to the prompt template.\n",
    "    esbmc_output_token_len: int = num_tokens_from_string(esbmc_output)\n",
    "\n",
    "    # 0 based, pass full ESBMC output to get error line\n",
    "    err_line: int = get_source_code_err_line_clang(data_esbmc_output_1[file_name_key], f\"samples-patched/{file_name_key}\") - 1\n",
    "\n",
    "    # Trim the source code in order to give it to the LLM.\n",
    "    lower_bound: int = get_lower_bound(source_code_lines, err_line, esbmc_output_token_len * 0.9)\n",
    "    # The upper bound is inclusive.\n",
    "    upper_bound: int = get_upper_bound(source_code_lines, err_line, esbmc_output_token_len * 0.1)\n",
    "    trimmed_sc: str = \"\".join(source_code_lines[lower_bound:upper_bound+1])\n",
    "    \n",
    "    try:\n",
    "        log_str(f\"LLM Raw Input:\\n{get_llm_message(prompt, trimmed_sc, esbmc_output, role)}\")\n",
    "        \n",
    "        delta: float = time()\n",
    "        # Role will be passed, if the prompt does not contain {role} then it will be not used.\n",
    "        llm_output_raw = run_sample(prompt, trimmed_sc, esbmc_output, role)\n",
    "        delta = time() - delta\n",
    "\n",
    "        log_str(f\"Raw Response:\\n\\n{llm_output_raw}\")\n",
    "        print_and_log(f\"Notice: Duration: {delta}\")\n",
    "        \n",
    "        llm_output = get_code_from_solution(llm_output_raw)\n",
    "        log_str(f\"Extracted Code:\\n\\n{llm_output}\")\n",
    "        \n",
    "        # Save patch\n",
    "        with open(f\"results-2/{file_name}\", \"w\") as file:\n",
    "            file.write(llm_output)\n",
    "\n",
    "        # Stitch together patch\n",
    "        patched_source: str = apply_patch_brutal_replacement(source_code, llm_output, lower_bound, upper_bound)\n",
    "\n",
    "        # Save patched source\n",
    "        with open(f\"samples-patched-2/{file_name}\", \"w\") as file:\n",
    "            file.write(patched_source)\n",
    "    except Exception as e:\n",
    "        print_and_log(f\"Notice: error: {file_name_key}: {e}\")\n",
    "    \n",
    "    print_and_log()\n",
    "\n",
    "    log_file.flush()\n",
    "    \n",
    "    # Write progress\n",
    "    with open(\"progress-2.txt\", \"a\") as file:\n",
    "        # Write the file name and subdirectory in progress in order to know which file is being\n",
    "        # processed in what subdirectory.\n",
    "        file.write(f\"{file_name}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2153367f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print_and_log()\n",
    "print_and_log(\"Running Contextual Strategy: 2nd Iteration Clang Assist\")\n",
    "\n",
    "# Loop through clang files\n",
    "for file_name_key in clang_file_keys:\n",
    "    file_name_split: list[str] = file_name_key.split(\".\")\n",
    "    \n",
    "    # Get prompt from file\n",
    "    prompt_idx: int = int(file_name_split[0])\n",
    "    # Get role from file\n",
    "    role_idx: int = int(file_name_split[1])\n",
    "    # Get CE/VP from file\n",
    "    esbmc_output_type: str = file_name_split[2]\n",
    "    # Get file_idx\n",
    "    file_idx: int = int(file_name_split[3])\n",
    "\n",
    "    # Check if file has already been processed and skip.\n",
    "    if os.path.exists(\"progress-2.txt\"):\n",
    "        with open(\"progress-2.txt\", \"r\") as file:\n",
    "            progress_files: list[str] = file.read().splitlines()\n",
    "            file_name: str = f\"{prompt_idx}.{role_idx}.{file_idx}.{os.path.basename(file_name_key)}\"\n",
    "            if file_name in progress_files:\n",
    "                log_str(f\"Skipping already processed file: {file_name}\")\n",
    "                continue\n",
    "\n",
    "    if \"VERIFICATION\" in data_esbmc_output_1[file_name_key]:\n",
    "        print_and_log(f\"Skipping {file_idx} {file_name_key} as it has VERIFICATION\")\n",
    "        continue\n",
    "\n",
    "    run_contextual_sample_clang(\n",
    "        prompt_idx=prompt_idx, \n",
    "        role_idx=role_idx, \n",
    "        file_idx=file_idx,\n",
    "        file_name_key=file_name_key,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1e6d83",
   "metadata": {},
   "source": [
    "# Unit Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88ad54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    "\n",
    "class TestNotebook(unittest.TestCase):\n",
    "    \n",
    "    def test_get_code_from_solution(self):\n",
    "        self.assertEqual(get_code_from_solution(\"This is a code block:\\n\\n```c\\naaa\\n```\"), \"aaa\")\n",
    "        self.assertEqual(get_code_from_solution(\"This is a code block:\\n\\n```\\nabc\\n```\"), \"abc\")\n",
    "        self.assertEqual(get_code_from_solution(\"This is a code block:```abc\\n```\"), \"This is a code block:```abc\\n```\")\n",
    "\n",
    "    def test_apply_brutal_replacement_strategy(self):\n",
    "        text = \"\\n\".join([\"a\", \"b\", \"c\", \"d\", \"e\", \"f\", \"g\"])\n",
    "        answer = \"\\n\".join([\"a\", \"b\", \"1\", \"g\"])\n",
    "        self.assertEqual(apply_patch_brutal_replacement(text, \"1\", 2, 5), answer)\n",
    "        text = \"\\n\".join([\"a\", \"b\", \"c\", \"d\", \"e\", \"f\", \"g\"])\n",
    "        answer = \"\\n\".join([\"a\", \"b\", \"c\", \"1\", \"e\", \"f\", \"g\"])\n",
    "        self.assertEqual(apply_patch_brutal_replacement(text, \"1\", 3, 3), answer)\n",
    "\n",
    "    def test_get_source_code_err_line(self):\n",
    "        self.assertEqual(get_source_code_err_line(data_esbmc_output[\"reinforcement_learning/cartpole_48_safe.c-amalgamation-6.c\"]), 323)\n",
    "        self.assertEqual(get_source_code_err_line(data_esbmc_output[\"reinforcement_learning/cartpole_92_safe.c-amalgamation-14.c\"]), 221)\n",
    "        self.assertEqual(get_source_code_err_line(data_esbmc_output[\"reinforcement_learning/cartpole_95_safe.c-amalgamation-80.c\"]), 285)\n",
    "        self.assertEqual(get_source_code_err_line(data_esbmc_output[\"reinforcement_learning/cartpole_26_safe.c-amalgamation-74.c\"]), 299)\n",
    "        self.assertEqual(get_source_code_err_line(data_esbmc_output[\"reach_prob_density/robot_5_safe.c-amalgamation-13.c\"]), 350)\n",
    "        self.assertEqual(get_source_code_err_line(data_esbmc_output[\"reach_prob_density/vdp_1_safe.c-amalgamation-28.c\"]), 247)\n",
    "\n",
    "    def test_get_lower_bound(self):\n",
    "        source_code: str = data_samples[\"reinforcement_learning/cartpole_48_safe.c-amalgamation-6.c\"]\n",
    "        source_code_lines: list[str] = source_code.splitlines(True)\n",
    "\n",
    "        # Test the additional tokens and if they affect the line.\n",
    "        self.assertEqual(get_lower_bound(source_code_lines, 323, 0), 176)\n",
    "        self.assertEqual(get_lower_bound(source_code_lines, 323, 500), 177)\n",
    "        self.assertEqual(get_lower_bound(source_code_lines, 323, 1000), 178)\n",
    "        \n",
    "        # Test if the length is accounted for.\n",
    "        self.assertLess(num_tokens_from_string(source_code[174:323]), LTOKENS)\n",
    "        self.assertLess(num_tokens_from_string(source_code[175:323]), LTOKENS - 500)\n",
    "        self.assertLess(num_tokens_from_string(source_code[176:323]), LTOKENS - 1000)\n",
    "    \n",
    "    def test_get_upper_bound(self):\n",
    "        source_code: str = data_samples[\"reach_prob_density/robot_5_safe.c-amalgamation-13.c\"]\n",
    "        source_code_lines: list[str] = source_code.splitlines(True)\n",
    "        \n",
    "        # Test the additional tokens and if they affect the line.\n",
    "        self.assertEqual(get_upper_bound(source_code_lines, 323, 0), 444)\n",
    "        self.assertEqual(get_upper_bound(source_code_lines, 323, 500), 422)\n",
    "        self.assertEqual(get_upper_bound(source_code_lines, 323, 1000), 379)\n",
    "\n",
    "        # Test if the length is accounted for.\n",
    "        self.assertLess(num_tokens_from_string(source_code[323:444]), UTOKENS)\n",
    "        self.assertLess(num_tokens_from_string(source_code[323:422]), UTOKENS - 500)\n",
    "        self.assertLess(num_tokens_from_string(source_code[323:379]), UTOKENS - 1000)\n",
    "\n",
    "    def test_get_esbmc_output_sized(self):\n",
    "        esbmc_output: str = data_esbmc_output[\"reach_prob_density/gcas_5_safe.c-amalgamation-149.c\"]\n",
    "        self.assertGreater(num_tokens_from_string(esbmc_output), MAX_ESBMC_OUTPUT)\n",
    "        self.assertLessEqual(num_tokens_from_string(get_esbmc_output_sized(esbmc_output)), MAX_ESBMC_OUTPUT)\n",
    "\n",
    "unittest.main(argv=[''], verbosity=2, exit=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wp3-f2e6c5a6839f1cbe0979a29147ac30fb",
   "language": "python",
   "name": "wp3-f2e6c5a6839f1cbe0979a29147ac30fb"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
